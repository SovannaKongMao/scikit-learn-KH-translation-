.. _introduction:

ការណែនាំអំពី Machine Learning ជាមួយ scikit-learn
=====================================================

.. topic:: ខ្លឹមសារនៃផ្នែក

នៅក្នុងផ្នែកនេះ យើងណែនាំវាក្យសព្ទនៃការរៀនម៉ាស៊ីន ដែលយើងប្រើទូទាំង scikit-learn និងផ្តល់ឧទាហរណ៍ការរៀនសាមញ្ញមួយ។

ការរៀនម៉ាស៊ីន៖ ការកំណត់បញ្ហា
-------------------------------------
ជាទូទៅបញ្ហាសិក្សាពិចារណាលើសំណុំនៃគំរូnនៃទិន្នន័យហើយបន្ទាប់មកព្យាយាមទស្សន៍ទាយលក្ខណៈសម្បត្តិនៃទិន្នន័យដែលមិនស្គាល់។ប្រសិនបើគំរូនីមួយៗមានច្រើនជាងលេខតែមួយ ហើយឧទាហរណ៍ធាតុពហុវិមាត្រ(aka multivariate data ) 

ការសិក្សាពីបញ្ហាត្រូវបានចែកចេញជាច្រើនចំណុច:
ការសិក្សាដែលត្រួតពិនិត្យ, ដែលទិន្នន័យមកជាមួយគុណលក្ខណៈបន្ថែមដែលយើងចង់ទស្សន៍ទាយ (:ref:`ចុចទីនេះ <supervised-learning>` ដើម្បីចូលទៅកាន់ទំព័រសិក្សាដែលគ្រប់គ្រងដោយ scikit-learn)) បញ្ហានេះអាចជា៖
-	ការចាត់ថ្នាក់៖ គំរូជាកម្មសិទ្ធិរបស់ថ្នាក់ពីរ ឬច្រើន ហើយយើងចង់រៀនពីទិន្នន័យដែលមានស្លាករួចហើយ របៀបទស្សន៍ទាយថ្នាក់នៃទិន្នន័យដែលមិនមានស្លាក។ ឧទាហរណ៍នៃបញ្ហានៃការចាត់ថ្នាក់នឹងជាការសម្គាល់លេខដែលសរសេរដោយដៃ ដែលក្នុងនោះគោលបំណងគឺត្រូវចាត់បញ្ចូលវ៉ិចទ័របញ្ចូលនីមួយៗទៅជាចំនួនកំណត់នៃប្រភេទដាច់ដោយឡែក។ វិធីមួយទៀតដើម្បីគិតពីការចាត់ថ្នាក់គឺជាទម្រង់ដាច់ដោយឡែកមួយ (ផ្ទុយទៅនឹងការបន្ត) នៃការសិក្សាដែលត្រូវបានគ្រប់គ្រង ដែលមួយប្រភេទមានកំណត់មួយចំនួន និងសម្រាប់គំរូនីមួយៗដែលបានផ្តល់ មួយគឺដើម្បីព្យាយាមដាក់ស្លាកពួកគេជាមួយនឹងប្រភេទ ឬថ្នាក់ត្រឹមត្រូវ .
-	តំរែតំរង់៖ ប្រសិនបើលទ្ធផលដែលចង់បានមានអថេរបន្តមួយ ឬច្រើន នោះកិច្ចការត្រូវបានគេហៅថា តំរែតំរង់។ ឧទាហរណ៍នៃបញ្ហាតំរែតំរង់គឺការព្យាករណ៍ប្រវែងនៃត្រីសាម៉ុងដែលជាមុខងារនៃអាយុនិងទម្ងន់របស់វា។

ការរៀនដែលគ្មានការត្រួតពិនិត្យ ដែលក្នុងនោះទិន្នន័យបណ្តុះបណ្តាលមានសំណុំនៃវ៉ិចទ័របញ្ចូល x ដោយគ្មានតម្លៃគោលដៅដែលត្រូវគ្នា។ គោលដៅនៅក្នុងបញ្ហាបែបនេះអាចជាការស្វែងរកក្រុមនៃឧទាហរណ៍ស្រដៀងគ្នានៅក្នុងទិន្នន័យ ដែលវាត្រូវបានគេហៅថាជាចង្កោម ឬដើម្បីកំណត់ការចែកចាយទិន្នន័យក្នុងចន្លោះបញ្ចូល ដែលគេស្គាល់ថាជាការប៉ាន់ប្រមាណដង់ស៊ីតេ ឬដើម្បីបញ្ចាំងទិន្នន័យពីវិមាត្រខ្ពស់ ដកឃ្លាទៅជាវិមាត្រពីរ ឬបីសម្រាប់គោលបំណងនៃការមើលឃើញ (:ref:`ចុចទីនេះ <unsupervised-learning>` ដើម្បីចូលទៅកាន់ទំព័រសិក្សាគ្មានការត្រួតពិនិត្យ Scikit-Learn)។

សំណុំបណ្តុះបណ្តាល និងឈុតសាកល្បង
ការរៀនម៉ាស៊ីនគឺអំពីការរៀនលក្ខណៈសម្បត្តិមួយចំនួននៃសំណុំទិន្នន័យ ហើយបន្ទាប់មកសាកល្បងលក្ខណៈសម្បត្តិទាំងនោះប្រឆាំងនឹងសំណុំទិន្នន័យផ្សេងទៀត។ ការអនុវត្តទូទៅក្នុងការរៀនម៉ាស៊ីនគឺដើម្បីវាយតម្លៃក្បួនដោះស្រាយដោយបែងចែកសំណុំទិន្នន័យជាពីរ។ យើងហៅឈុតមួយក្នុងចំនោមឈុតទាំងនោះថា ឈុតហ្វឹកហាត់ ដែលយើងរៀនពីលក្ខណៈសម្បត្តិមួយចំនួន។ យើងហៅមួយទៀតថា សំណុំតេស្ត ដែលយើងសាកល្បងលក្ខណៈសម្បត្តិដែលបានរៀន។

បញ្ចូលទិន្នន័យឧទាហរណ៍
scikit-learn ភ្ជាប់មកជាមួយសំណុំទិន្នន័យស្តង់ដារមួយចំនួន ឧទាហរណ៍ សំណុំទិន្នន័យ iris និងខ្ទង់សម្រាប់ការចាត់ថ្នាក់ និងសំណុំទិន្នន័យជំងឺទឹកនោមផ្អែមសម្រាប់ការតំរែតំរង់។

ខាងក្រោមនេះ យើងចាប់ផ្តើមអ្នកបកប្រែ Python ពីសែលរបស់យើង ហើយបន្ទាប់មកផ្ទុកសំណុំទិន្នន័យ iris និងខ្ទង់។ អនុសញ្ញាកំណត់ចំណាំរបស់យើងគឺថា $ តំណាងឱ្យ shell prompt ខណៈពេលដែល >>> បង្ហាញពីប្រអប់បញ្ចូលអ្នកបកប្រែ Python:

$ python
>>> from sklearn import datasets
>>> iris = datasets.load_iris()
>>> digits = datasets.load_digits()

សំណុំទិន្នន័យគឺជាវត្ថុស្រដៀងនឹងវចនានុក្រមដែលផ្ទុកទិន្នន័យទាំងអស់ និងទិន្នន័យមេតាមួយចំនួនអំពីទិន្នន័យ។ ទិន្នន័យនេះត្រូវបានរក្សាទុកក្នុង .data member ដែលជា n_samples, n_features array។ ក្នុងករណីនៃបញ្ហាដែលស្ថិតក្រោមការគ្រប់គ្រង អថេរឆ្លើយតបមួយ ឬច្រើនត្រូវបានរក្សាទុកក្នុងសមាជិក .target ។ ព័ត៌មានលម្អិតបន្ថែមអំពីសំណុំទិន្នន័យផ្សេងគ្នាអាចរកបាននៅក្នុង :ref:`ផ្នែកឧទ្ទិស <datasets>`។

ឧទាហរណ៍ ក្នុងករណីសំណុំទិន្នន័យខ្ទង់ digits.data ផ្តល់សិទ្ធិចូលប្រើមុខងារដែលអាចត្រូវបានប្រើដើម្បីចាត់ថ្នាក់គំរូលេខ៖
>>> print(digits.data)
[[ 0.   0.   5. ...   0.   0.   0.]
 [ 0.   0.   0. ...  10.   0.   0.]
 [ 0.   0.   0. ...  16.   9.   0.]
 ...
 [ 0.   0.   1. ...   6.   0.   0.]
 [ 0.   0.   2. ...  12.   0.   0.]
 [ 0.   0.  10. ...  12.   1.   0.]]

ហើយ digits.target ផ្តល់នូវការពិតសម្រាប់សំណុំទិន្នន័យខ្ទង់ នោះគឺជាលេខដែលត្រូវគ្នាទៅនឹងរូបភាពខ្ទង់នីមួយៗ ដែលយើងកំពុងព្យាយាមសិក្សា៖
>>> digits.target
array([0, 1, 2, ..., 8, 9, 8])

រូបរាងនៃអារេទិន្នន័យ
ទិន្នន័យគឺតែងតែជាអារេ 2D រូបរាង (n_samples, n_features) ទោះបីជាទិន្នន័យដើមអាចមានរូបរាងខុសគ្នាក៏ដោយ។ ក្នុងករណីលេខ គំរូដើមនីមួយៗគឺជារូបភាពនៃរូបរាង (8, 8) ហើយអាចចូលប្រើបានដោយប្រើ៖


>>> digits.images[0]
array([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],
       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],
       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],
       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],
       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],
       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],
       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],
       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])


គំរូ :ref:`simple example on this dataset <sphx_glr_auto_examples_classification_plot_digits_classification.py>` បង្ហាញពីរបៀបចាប់ផ្តើមពីបញ្ហាដើម ដែលវាអាចកំណត់ទិន្នន័យសម្រាប់ការប្រើប្រាស់នៅក្នុង scikit-learn ។

កំពុងផ្ទុកពីសំណុំទិន្នន័យខាងក្រៅ

ដើម្បីផ្ទុកពីសំណុំទិន្នន័យខាងក្រៅ សូមយោងទៅ :ref:`loading external datasets <external_datasets>`.។

ការរៀននិងការទស្សន៍ទាយ
ក្នុងករណីនៃសំណុំទិន្នន័យតួលេខ ភារកិច្ចគឺដើម្បីទស្សន៍ទាយ ដែលផ្តល់រូបភាព ដែលលេខនោះតំណាងឱ្យ។ យើងត្រូវបានផ្តល់គំរូនៃថ្នាក់នីមួយៗដែលអាចធ្វើបានទាំង 10 (ខ្ទង់ពីសូន្យដល់ប្រាំបួន) ដែលយើងសមនឹងអ្នកប៉ាន់ស្មាន(estimator) ដើម្បីអាចទស្សន៍ទាយថ្នាក់ដែលគំរូដែលមើលមិនឃើញជាកម្មសិទ្ធិ។

នៅក្នុង scikit-learn ការប៉ាន់ប្រមាណសម្រាប់ការចាត់ថ្នាក់គឺជាវត្ថុ Python ដែលអនុវត្តវិធី fit(X, y) និងpredict(T) ។

ឧទាហរណ៍នៃការប៉ាន់ប្រមាណគឺជាថ្នាក់ sklearn.svm.SVC ដែលអនុវត្តការចាត់ថ្នាក់វ៉ិចទ័រគាំទ្រ។ អ្នកបង្កើតការប៉ាន់ប្រមាណយកជាអាគុយម៉ង់ប៉ារ៉ាម៉ែត្ររបស់គំរូ។

សម្រាប់ពេលនេះ យើងនឹងពិចារណាការប៉ាន់ប្រមាណជាប្រអប់ខ្មៅ៖
>>> from sklearn import svm
>>> clf = svm.SVC(gamma=0.001, C=100.)

ការជ្រើសរើសប៉ារ៉ាម៉ែត្រនៃគំរូ

ក្នុងឧទាហរណ៍នេះ យើងកំណត់តម្លៃហ្គាម៉ា(Gamma)ដោយដៃ។ ដើម្បីស្វែងរកតម្លៃល្អសម្រាប់ប៉ារ៉ាម៉ែត្រទាំងនេះ យើងអាចប្រើឧបករណ៍ដូចជា :ref:`grid search <grid_search>` និង :ref:`cross validation <cross_validation>`។

ការប៉ាន់ស្មាន clf (សម្រាប់ចាត់ថ្នាក់) ត្រូវបានបំពាក់ជាលើកដំបូងទៅនឹងគំរូ។ នោះគឺវាត្រូវតែរៀនពីគំរូ។ នេះត្រូវបានធ្វើដោយការឆ្លងកាត់សំណុំការបណ្តុះបណ្តាលរបស់យើងទៅនឹងវិធីសាស្ត្រសម។ សម្រាប់ឈុតបណ្តុះបណ្តាល យើងនឹងប្រើរូបភាពទាំងអស់ពីសំណុំទិន្នន័យរបស់យើង លើកលែងតែរូបភាពចុងក្រោយ ដែលយើងនឹងរក្សាទុកសម្រាប់ការទស្សន៍ទាយរបស់យើង។ យើងជ្រើសរើសសំណុំបណ្ដុះបណ្ដាលជាមួយ [:-1] វាក្យសម្ព័ន្ធ Python ដែលបង្កើតអារេថ្មីដែលមានធាតុទាំងអស់លើកលែងតែធាតុចុងក្រោយពី digits.data៖
>>> clf.fit(digits.data[:-1], digits.target[:-1])
SVC(C=100.0, gamma=0.001)

ឥឡូវនេះអ្នកអាចទស្សន៍ទាយតម្លៃថ្មី។ ក្នុងករណីនេះ អ្នកនឹងទស្សន៍ទាយដោយប្រើរូបភាពចុងក្រោយពី digits.data។ តាមរយៈការទស្សន៍ទាយ អ្នកនឹងកំណត់រូបភាពពីឈុតហ្វឹកហាត់ដែលត្រូវនឹងរូបភាពចុងក្រោយបំផុត។
>>> clf.predict(digits.data[-1:])
array([8])
រូបភាព ៖














ដូចដែលអ្នកអាចមើលឃើញ វាគឺជាកិច្ចការដ៏លំបាកមួយ៖ បន្ទាប់ពីទាំងអស់ រូបភាពមានគុណភាពមិនច្បាស់។ តើអ្នកយល់ស្របនឹងអ្នកចាត់ថ្នាក់ទេ?

ឧទាហរណ៍ពេញលេញនៃបញ្ហាចំណាត់ថ្នាក់នេះគឺមានជាឧទាហរណ៍ដែលអ្នកអាចដំណើរការ និងសិក្សាបាន៖ :ref:`sphx_glr_auto_examples_classification_plot_digits_classification.py`.

អនុសញ្ញា(Conventions)
ការប៉ាន់ស្មាន scikit-learn អនុវត្តតាមច្បាប់ជាក់លាក់ ដើម្បីធ្វើឱ្យអាកប្បកិរិយារបស់ពួកគេកាន់តែអាចទស្សន៍ទាយបាន។ ទាំងនេះត្រូវបានពិពណ៌នាលម្អិតបន្ថែមទៀតក្នុង :ref:`glossary`។

ការវាយបញ្ចូល(Type Casting)
ប្រសិនបើអាចធ្វើទៅបាន ការបញ្ចូលប្រភេទ float32 នឹងរក្សាប្រភេទទិន្នន័យរបស់វា។ បើមិនដូច្នេះទេ ការបញ្ចូលនឹងត្រូវបានបោះទៅ float64៖
>>> import numpy as np
>>> from sklearn import kernel_approximation

>>> rng = np.random.RandomState(0)
>>> X = rng.rand(10, 2000)
>>> X = np.array(X, dtype='float32')
>>> X.dtype
dtype('float32')

>>> transformer = kernel_approximation.RBFSampler()
>>> X_new = transformer.fit_transform(X)
>>> X_new.dtype
dtype('float32')



ក្នុងឧទាហរណ៍នេះ X គឺ float32 ហើយមិនផ្លាស់ប្តូរដោយ fit_transform(X)។

ការប្រើទិន្នន័យហ្វឹកហ្វឺនប្រភេទ float32 (ឬការធ្វើតេស្ត) ជាញឹកញាប់មានប្រសិទ្ធភាពជាងការប្រើ float64 dtype ធម្មតា៖ វាអនុញ្ញាតឱ្យកាត់បន្ថយការប្រើប្រាស់អង្គចងចាំ ហើយពេលខ្លះក៏កាត់បន្ថយពេលវេលាដំណើរការដោយប្រើប្រាស់ការណែនាំវ៉ិចទ័ររបស់ស៊ីភីយូ។ ទោះយ៉ាងណាក៏ដោយ ពេលខ្លះវាអាចនាំឱ្យមានបញ្ហាស្ថិរភាពជាលេខ ដែលបណ្តាលឱ្យក្បួនដោះស្រាយមានភាពរសើបជាងមុនចំពោះមាត្រដ្ឋាននៃតម្លៃ និង :ref:`require adequate preprocessing<preprocessing_scaler>`.

ទោះជាយ៉ាងណាក៏ដោយ សូមចងចាំថា មិនមែនអ្នកប៉ាន់ស្មាន scikit-learn ទាំងអស់ព្យាយាមធ្វើការនៅក្នុងរបៀប float32 នោះទេ។ ជាឧទាហរណ៍ ឧបករណ៍បំលែងមួយចំនួននឹងតែងតែបញ្ជូនធាតុចូលរបស់ពួកគេទៅ float64 ហើយត្រឡប់តម្លៃបំលែង float64 ជាលទ្ធផល។


គោលដៅតំរែតំរង់ត្រូវបានបោះទៅ float64 ហើយគោលដៅចាត់ថ្នាក់ត្រូវបានរក្សាទុក:
>>> from sklearn import datasets
>>> from sklearn.svm import SVC
>>> iris = datasets.load_iris()
>>> clf = SVC()
>>> clf.fit(iris.data, iris.target)
SVC()

>>> list(clf.predict(iris.data[:3]))
[0, 0, 0]

>>> clf.fit(iris.data, iris.target_names[iris.target])
SVC()

>>> list(clf.predict(iris.data[:3]))
['setosa', 'setosa', 'setosa']
នៅទីនេះ predict () ដំបូងត្រឡប់អារេចំនួនគត់ ចាប់តាំងពី iris.target (អារេចំនួនគត់) ត្រូវបានប្រើក្នុងសម។ predict () ទីពីរ ត្រត្រឡប់អារេខ្សែអក្សរ ចាប់តាំងពី iris.target_names ឪ្យសាកសម។

ការកែលម្អនិងធ្វើបច្ចុប្បន្នភាពប៉ារ៉ាម៉ែត្រ
Hyper-parameters នៃការប៉ាន់ស្មានអាចត្រូវបានធ្វើបច្ចុប្បន្នភាពបន្ទាប់ពីវាត្រូវបានបង្កើតតាមរយៈ :term:`set_params()<set_params>`method។ ការហៅ fit() ច្រើនជាងមួយដងនឹងសរសេរជាន់លើអ្វីដែលបានរៀនដោយfit()ពីមុនមក។
>>> import numpy as np
>>> from sklearn.datasets import load_iris
>>> from sklearn.svm import SVC
>>> X, y = load_iris(return_X_y=True)

>>> clf = SVC()
>>> clf.set_params(kernel='linear').fit(X, y)
SVC(kernel='linear')
>>> clf.predict(X[:5])
array([0, 0, 0, 0, 0])

>>> clf.set_params(kernel='rbf').fit(X, y)
SVC()
>>> clf.predict(X[:5])
array([0, 0, 0, 0, 0])

នៅទីនេះ, ខឺណែល rbf លំនាំដើមដំបូងត្រូវបានប្តូរទៅជាលីនេអ៊ែរតាមរយៈ :func:`SVC.set_params()<sklearn.svm.SVC.set_params>`បន្ទាប់ពីឧបករណ៍ប៉ាន់ស្មានត្រូវបានសាងសង់ ហើយប្តូរត្រលប់ទៅ rbf វិញ ដើម្បីកែតម្រូវការប៉ាន់ស្មាន និងបង្កើត ការព្យាករណ៍ទីពីរ។
Multiclass ទល់នឹង multilabel សម
នៅពេលប្រើ :class:`multiclass classifiers <sklearn.multiclass>`កិច្ចការសិក្សា និងការទស្សន៍ទាយដែលត្រូវបានអនុវត្តគឺអាស្រ័យលើទម្រង់នៃទិន្នន័យគោលដៅដែលត្រូវនឹង៖
>>> from sklearn.svm import SVC
>>> from sklearn.multiclass import OneVsRestClassifier
>>> from sklearn.preprocessing import LabelBinarizer

>>> X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]
>>> y = [0, 0, 1, 1, 2]

>>> classif = OneVsRestClassifier(estimator=SVC(random_state=0))
>>> classif.fit(X, y).predict(X)
array([0, 0, 1, 1, 2])
ក្នុងករណីខាងលើ អ្នកចាត់ថ្នាក់គឺសមនៅលើអារេ 1d នៃស្លាកពហុថ្នាក់ ហើយ predict () ដូច្នេះផ្តល់នូវការព្យាករណ៍ពហុវណ្ណៈដែលត្រូវគ្នា។ វាក៏អាចធ្វើទៅបានផងដែរក្នុងការបំពាក់លើអារេ 2d នៃសូចនាករស្លាកសញ្ញាគោលពីរ៖
>>> y = LabelBinarizer().fit_transform(y)
>>> classif.fit(X, y).predict(X)
array([[1, 0, 0],
       [1, 0, 0],
       [0, 1, 0],
       [0, 0, 0],
       [0, 0, 0]])
នៅទីនេះ អ្នកចាត់ថ្នាក់គឺfit() នៅលើតំណាងស្លាកសញ្ញាគោលពីរនៃ y ដោយប្រើ :class:`LabelBinarizer <sklearn.preprocessing.LabelBinarizer>`។ ក្នុងករណីនេះ predict() ត្រឡប់អារេ 2d ដែលតំណាងឱ្យការព្យាករណ៍ពហុស្លាកដែលត្រូវគ្នា។

ចំណាំថាករណីទី 4 និងទី 5 ត្រឡប់លេខសូន្យទាំងអស់ ដែលបង្ហាញថាពួកគេមិនត្រូវគ្នានឹងស្លាកណាមួយក្នុងចំណោមស្លាកទាំងបីដែលសមស្រប។ ជាមួយនឹងលទ្ធផលពហុស្លាក វាអាចទៅរួចដូចគ្នាសម្រាប់ឧទាហរណ៍មួយដែលត្រូវកំណត់ស្លាកច្រើន៖


>>> from sklearn.preprocessing import MultiLabelBinarizer
>>> y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]
>>> y = MultiLabelBinarizer().fit_transform(y)
>>> classif.fit(X, y).predict(X)
array([[1, 1, 0, 0, 0],
       [1, 0, 1, 0, 0],
       [0, 1, 0, 1, 0],
       [1, 0, 1, 0, 0],
       [1, 0, 1, 0, 0]])
ក្នុងករណីនេះ អ្នកចាត់ថ្នាក់គឺសមនឹងករណីនីមួយៗដែលបានកំណត់ស្លាកច្រើន។ :class:`MultiLabelBinarizer <sklearn.preprocessing.MultiLabelBinarizer>` ត្រូវបានប្រើដើម្បី binarize អារេ 2d នៃ multilabels ដែលត្រូវនឹង។ ជាលទ្ធផល predict() ត្រឡប់អារេ 2d ដែលមានស្លាកព្យាករណ៍ជាច្រើនសម្រាប់ឧទាហរណ៍នីមួយៗ។