កំហុសទូទៅ និងការអនុវត្តដែលបានណែនាំ
គោលបំណងនៃជំពូកនេះគឺដើម្បីបង្ហាញពីភាពលំបាកទូទៅមួយចំនួន និងការប្រឆាំងនឹងលំនាំដែលកើតឡើងនៅពេលប្រើ scikit-learn ។ វាផ្តល់នូវឧទាហរណ៍នៃអ្វីដែលមិនគួរធ្វើ រួមជាមួយនឹងឧទាហរណ៍ត្រឹមត្រូវដែលត្រូវគ្នា។

ដំណើរការមុនមិនស៊ីសង្វាក់គ្នា។
scikit-learn ផ្តល់បណ្ណាល័យនៃ :ref:`data-transforms` ដែលអាចសម្អាត (សូមមើល :ref:`preprocessing`) កាត់បន្ថយ (សូមមើល :ref:`data_reduction`) ពង្រីក (សូមមើល :ref:`kernel_approximation`) ឬបង្កើត (សូមមើល៖ ref:`feature_extraction`) តំណាងលក្ខណៈ។ ប្រសិនបើការបំប្លែងទិន្នន័យទាំងនេះត្រូវបានប្រើនៅពេលបណ្តុះបណ្តាលគំរូ ពួកវាក៏ត្រូវតែប្រើនៅលើសំណុំទិន្នន័យជាបន្តបន្ទាប់ផងដែរ ថាតើវាជាទិន្នន័យសាកល្បង ឬទិន្នន័យនៅក្នុងប្រព័ន្ធផលិតកម្ម។ បើមិនដូច្នេះទេ ទំហំមុខងារនឹងផ្លាស់ប្តូរ ហើយម៉ូដែលនឹងមិនអាចដំណើរការប្រកបដោយប្រសិទ្ធភាពបានទេ។

សម្រាប់ឧទាហរណ៍ខាងក្រោម ចូរយើងបង្កើតសំណុំទិន្នន័យសំយោគជាមួយនឹងមុខងារតែមួយ៖

>>> ពី sklearn.datasets នាំចូល make_regression
>>> ពី sklearn.model_selection import train_test_split

>>> random_state = ៤២
>>> X, y = make_regression(random_state=random_state, n_features=1, noise=1)
>>> X_train, X_test, y_train, y_test = train_test_split(
... X, y, test_size=0.4, random_state=random_state)
ខុស

សំណុំទិន្នន័យរថភ្លើងត្រូវបានធ្វើមាត្រដ្ឋាន ប៉ុន្តែមិនមែនជាសំណុំទិន្នន័យសាកល្បងទេ ដូច្នេះការអនុវត្តគំរូនៅលើសំណុំទិន្នន័យសាកល្បងគឺអាក្រក់ជាងការរំពឹងទុក៖

>>> ពី sklearn.metrics នាំចូល mean_squared_error
>>> ពី sklearn.linear_model នាំចូល LinearRegression
>>> ពី sklearn.preprocessing import StandardScaler

>>> មាត្រដ្ឋាន = StandardScaler()
>>> X_train_transformed = scaler.fit_transform(X_train)
>>> model = LinearRegression().fit(X_train_transformed, y_train)
>>> mean_squared_error(y_test, model.predict(X_test))
62.80...
ត្រូវហើយ។

ជំនួសឱ្យការឆ្លងកាត់ X_test ដែលមិនផ្លាស់ប្តូរដើម្បីទស្សន៍ទាយ យើងគួរតែបំប្លែងទិន្នន័យសាកល្បង វិធីដូចគ្នាដែលយើងបំប្លែងទិន្នន័យបណ្តុះបណ្តាល៖

>>> X_test_transformed = scaler.transform(X_test)
>>> mean_squared_error(y_test, model.predict(X_test_transformed))
0.90...

ជាជម្រើស យើងសូមណែនាំឱ្យប្រើ :class:`Pipeline <sklearn.pipeline.Pipeline>` ដែលធ្វើឱ្យវាកាន់តែងាយស្រួលក្នុងការផ្លាស់ប្តូរខ្សែសង្វាក់ជាមួយអ្នកប៉ាន់ប្រមាណ និងកាត់បន្ថយលទ្ធភាពនៃការបំភ្លេចការផ្លាស់ប្តូរមួយ៖

>>> ពី sklearn.pipeline នាំចូល make_pipeline

>>> model = make_pipeline(StandardScaler(), LinearRegression())
>>> model.fit(X_train, y_train)
Pipeline(ជំហាន=[('standardscaler', StandardScaler()),
                 ('linearregression', LinearRegression()])
>>> mean_squared_error(y_test, model.predict(X_test))
0.90...
បំពង់បង្ហូរប្រេងក៏ជួយជៀសវាងបញ្ហាទូទៅមួយទៀតផងដែរ៖ ការលេចធ្លាយទិន្នន័យសាកល្បងទៅក្នុងទិន្នន័យបណ្តុះបណ្តាល។

ការលេចធ្លាយទិន្នន័យ
ការលេចធ្លាយទិន្នន័យកើតឡើងនៅពេលដែលព័ត៌មានដែលនឹងមិនអាចរកបាននៅពេលទស្សន៍ទាយត្រូវបានប្រើនៅពេលបង្កើតគំរូ។ នេះបណ្តាលឱ្យមានការប៉ាន់ប្រមាណការអនុវត្តប្រកបដោយសុទិដ្ឋិនិយមលើសលប់ ឧទាហរណ៍ពី :ref:`សុពលភាពឆ្លង <cross_validation>` ហើយដូច្នេះការអនុវត្តកាន់តែអន់នៅពេលដែលគំរូត្រូវបានប្រើប្រាស់លើទិន្នន័យថ្មីជាក់ស្តែង ឧទាហរណ៍ក្នុងអំឡុងពេលផលិត។

មូលហេតុទូទៅមួយគឺការមិនរក្សាសំណុំរងទិន្នន័យសាកល្បង និងបណ្តុះបណ្តាលដាច់ដោយឡែក។ ទិន្នន័យសាកល្បងមិនគួរត្រូវបានប្រើដើម្បីធ្វើការជ្រើសរើសអំពីគំរូនោះទេ។ ច្បាប់ទូទៅគឺមិនត្រូវហៅសមនៅលើទិន្នន័យតេស្តនោះទេ។ ខណៈពេលដែលវាអាចស្តាប់ទៅជាក់ស្តែង វាងាយស្រួលក្នុងការខកខានក្នុងករណីខ្លះ ឧទាហរណ៍នៅពេលអនុវត្តជំហានមុនដំណើរការជាក់លាក់។

ទោះបីជាសំណុំរងទិន្នន័យរថភ្លើង និងសាកល្បងទាំងពីរគួរតែទទួលបានការផ្លាស់ប្តូរដំណើរការមុនដូចគ្នា (ដូចដែលបានពិពណ៌នានៅក្នុងផ្នែកមុន) វាជាការសំខាន់ដែលការបំប្លែងទាំងនេះត្រូវបានរៀនតែពីទិន្នន័យបណ្តុះបណ្តាលប៉ុណ្ណោះ។ ឧទាហរណ៍ ប្រសិនបើអ្នកមានជំហានធម្មតាដែលអ្នកបែងចែកដោយតម្លៃមធ្យម ជាមធ្យមគួរតែជាមធ្យមនៃសំណុំរងរថភ្លើង មិនមែនជាមធ្យមនៃទិន្នន័យទាំងអស់នោះទេ។ ប្រសិនបើសំណុំរងសាកល្បងត្រូវបានរួមបញ្ចូលក្នុងការគណនាជាមធ្យមនោះ ព័ត៌មានពីសំណុំរងសាកល្បងគឺមានឥទ្ធិពលលើគំរូ។

ឧទាហរណ៍នៃការលេចធ្លាយទិន្នន័យកំឡុងពេលដំណើរការមុនត្រូវបានរៀបរាប់ខាងក្រោម។

ការលេចធ្លាយទិន្នន័យកំឡុងពេលដំណើរការមុន។
ចំណាំ

យើងនៅទីនេះជ្រើសរើសដើម្បីបង្ហាញពីការលេចធ្លាយទិន្នន័យជាមួយនឹងជំហានជ្រើសរើសលក្ខណៈពិសេស។ ទោះបីជាយ៉ាងណាក៏ដោយ ហានិភ័យនៃការលេចធ្លាយនេះគឺពាក់ព័ន្ធជាមួយនឹងការបំប្លែងស្ទើរតែទាំងអស់នៅក្នុង scikit-learn រួមទាំង (ប៉ុន្តែមិនកំណត់ចំពោះ): class:`~sklearn.preprocessing.StandardScaler`, :class:`~sklearn.impute.SimpleImputer` និង :class :`~sklearn.decomposition.PCA` ។

មុខងារ :ref:`feature_selection` មួយចំនួនមាននៅក្នុង scikit-learn។ ពួកវាអាចជួយលុបលក្ខណៈពិសេសដែលមិនពាក់ព័ន្ធ លែងត្រូវការគ្នា និងគ្មានសំឡេង ក៏ដូចជាធ្វើអោយប្រសើរឡើងនូវពេលវេលា និងដំណើរការនៃគំរូរបស់អ្នក។ ដូចនឹងប្រភេទផ្សេងទៀតនៃការដំណើរការមុន ការជ្រើសរើសមុខងារគួរតែប្រើតែទិន្នន័យបណ្តុះបណ្តាលប៉ុណ្ណោះ។ ការរួមបញ្ចូលទិន្នន័យសាកល្បងនៅក្នុងការជ្រើសរើសលក្ខណៈពិសេសនឹងលំអៀងដោយសុទិដ្ឋិនិយមចំពោះគំរូរបស់អ្នក។

ដើម្បីបង្ហាញ យើងនឹងបង្កើតបញ្ហាចំណាត់ថ្នាក់ប្រព័ន្ធគោលពីរនេះជាមួយនឹងលក្ខណៈពិសេសដែលបានបង្កើតដោយចៃដន្យចំនួន 10,000៖

>>> នាំចូល numpy ជា np
>>> n_samples, n_features, n_classes = 200, 10000, 2
>>> rng = np.random.RandomState(42)
>>> X = rng.standard_normal((n_samples, n_features))
>>> y = rng.choice(n_classes, n_samples)
ខុស

ការប្រើប្រាស់ទិន្នន័យទាំងអស់ដើម្បីធ្វើការជ្រើសរើសលក្ខណៈពិសេស នាំឱ្យពិន្ទុភាពត្រឹមត្រូវខ្ពស់ជាងឱកាស ទោះបីជាគោលដៅរបស់យើងគឺចៃដន្យទាំងស្រុងក៏ដោយ។ ភាពចៃដន្យនេះមានន័យថា X និង y របស់យើងគឺឯករាជ្យ ហើយយើងរំពឹងថាភាពត្រឹមត្រូវនឹងមានប្រហែល 0.5 ។ ទោះយ៉ាងណាក៏ដោយ ដោយសារជំហានជ្រើសរើសលក្ខណៈពិសេស 'មើលឃើញ' ទិន្នន័យសាកល្បង ម៉ូដែលនេះមានអត្ថប្រយោជន៍មិនយុត្តិធម៌។ នៅក្នុងឧទាហរណ៍មិនត្រឹមត្រូវខាងក្រោមជាដំបូង យើងប្រើទិន្នន័យទាំងអស់សម្រាប់ការជ្រើសរើសលក្ខណៈពិសេស ហើយបន្ទាប់មកបំបែកទិន្នន័យទៅជាផ្នែករងនៃការបណ្តុះបណ្តាល និងសាកល្បងសម្រាប់ការបំពេញគំរូ។ លទ្ធផលគឺខ្ពស់ជាងពិន្ទុភាពត្រឹមត្រូវដែលរំពឹងទុក៖

>>> ពី sklearn.model_selection import train_test_split
>>> ពី sklearn.feature_selection នាំចូល SelectKBest
>>> ពី sklearn.ensemble នាំចូល GradientBoostingClassifier
>>> ពី sklearn.metrics នាំចូល accuracy_score

>>> # ដំណើរការមុនមិនត្រឹមត្រូវ៖ ទិន្នន័យទាំងមូលត្រូវបានបំប្លែង
>>> X_selected = SelectKBest(k=25).fit_transform(X, y)

>>> X_train, X_test, y_train, y_test = train_test_split(
... X_selected, y, random_state=42)
>>> gbc = GradientBoostingClassifier(random_state=1)
>>> gbc.fit(X_train, y_train)
GradientBoostingClassifier(random_state=1)

>>> y_pred = gbc.predict(X_test)
>>> ពិន្ទុភាពត្រឹមត្រូវ (y_test, y_pred)
0.76

ត្រូវហើយ។

ដើម្បីបងា្ករការលេចធ្លាយទិន្នន័យ វាជាការអនុវត្តល្អក្នុងការបែងចែកទិន្នន័យរបស់អ្នកទៅជារថភ្លើង និងសាកល្បងសំណុំរងជាមុនសិន។ បន្ទាប់មកការជ្រើសរើសលក្ខណៈពិសេសអាចត្រូវបានបង្កើតឡើងដោយប្រើតែសំណុំទិន្នន័យរថភ្លើង។ សូមកត់សម្គាល់ថានៅពេលណាដែលយើងប្រើ fit ឬ fit_transform យើងប្រើតែសំណុំទិន្នន័យរថភ្លើងប៉ុណ្ណោះ។ ឥឡូវនេះពិន្ទុគឺជាអ្វីដែលយើងរំពឹងសម្រាប់ទិន្នន័យ ជិតដល់ឱកាសហើយ៖

>>> X_train, X_test, y_train, y_test = train_test_split(
... X, y, random_state=42)
>>> ជ្រើសរើស = SelectKBest(k=25)
>>> X_train_selected = select.fit_transform(X_train, y_train)

>>> gbc = GradientBoostingClassifier(random_state=1)
>>> gbc.fit(X_train_selected, y_train)
GradientBoostingClassifier(random_state=1)

>>> X_test_selected = select.transform(X_test)
>>> y_pred = gbc.predict(X_test_selected)
>>> ពិន្ទុភាពត្រឹមត្រូវ (y_test, y_pred)
0.46
នៅទីនេះម្តងទៀត យើងសូមណែនាំឱ្យប្រើ :class:`~sklearn.pipeline.Pipeline` ដើម្បីភ្ជាប់ជម្រើសនៃមុខងារ និងការប៉ាន់ប្រមាណគំរូ។ បំពង់បង្ហូរប្រេងធានាថាមានតែទិន្នន័យបណ្តុះបណ្តាលប៉ុណ្ណោះដែលត្រូវបានប្រើនៅពេលដំណើរការសម ហើយទិន្នន័យតេស្តត្រូវបានប្រើសម្រាប់តែការគណនាពិន្ទុភាពត្រឹមត្រូវប៉ុណ្ណោះ៖

>>> ពី sklearn.pipeline នាំចូល make_pipeline
>>> X_train, X_test, y_train, y_test = train_test_split(
... X, y, random_state=42)
>>> pipeline = make_pipeline(SelectKBest(k=25),
... GradientBoostingClassifier(random_state=1))
>>> pipeline.fit(X_train, y_train)
បំពង់(ជំហាន=[('selectkbest', SelectKBest(k=25)),
                 ('gradientboostingclassifier',
                 GradientBoostingClassifier(random_state=1))])

>>> y_pred = pipeline.predict(X_test)
>>> ពិន្ទុភាពត្រឹមត្រូវ (y_test, y_pred)
0.46

បំពង់បង្ហូរប្រេងក៏អាចត្រូវបានបញ្ចូលទៅក្នុងមុខងារឆ្លងកាត់សុពលភាពដូចជា :func:`~sklearn.model_selection.cross_val_score`។ ជា​ថ្មី​ម្តង​ទៀត បំពង់​ធានា​ថា​សំណុំ​រង​ទិន្នន័យ​ត្រឹមត្រូវ និង​វិធីសាស្ត្រ​ប៉ាន់​ប្រមាណ​ត្រូវ​បាន​ប្រើ​កំឡុង​ពេល​សម និង​ការ​ទស្សន៍ទាយ៖

>>> ពី sklearn.model_selection នាំចូល cross_val_score
>>> ពិន្ទុ = cross_val_score(pipeline, X, y)
>>> print(f"ភាពត្រឹមត្រូវមធ្យម៖ {scores.mean():.2f}+/-{scores.std():.2f}")
ភាពត្រឹមត្រូវជាមធ្យម៖ 0.45+/-0.07
វិធីជៀសវាងការលេចធ្លាយទិន្នន័យ
ខាង​ក្រោម​នេះ​ជា​គន្លឹះ​មួយ​ចំនួន​ដើម្បី​ជៀសវាង​ការ​លេច​ធ្លាយ​ទិន្នន័យ៖

តែងតែបំបែកទិន្នន័យទៅជាបណ្តុំរងរថភ្លើង និងសាកល្បងជាមុនសិន ជាពិសេសមុនពេលដំណើរការដំណើរការជាមុនណាមួយ។

កុំរួមបញ្ចូលទិន្នន័យសាកល្បងនៅពេលប្រើវិធី fit and fit_transform ។ ការប្រើទិន្នន័យទាំងអស់ ឧ. fit(X) អាចបណ្តាលឱ្យមានពិន្ទុសុទិដ្ឋិនិយមហួសហេតុ។

ផ្ទុយទៅវិញ វិធីសាស្ត្របំប្លែងគួរតែត្រូវបានប្រើទាំងលើរថភ្លើង និងសំណុំរងសាកល្បង ព្រោះការដំណើរការមុនដូចគ្នាគួរតែត្រូវបានអនុវត្តចំពោះទិន្នន័យទាំងអស់។ នេះអាចសម្រេចបានដោយប្រើ fit_transform នៅលើសំណុំរងរថភ្លើង និងបំប្លែងលើសំណុំរងសាកល្បង។

scikit-learn :ref:`pipeline <pipeline>` គឺជាមធ្យោបាយដ៏ល្អមួយដើម្បីការពារការលេចធ្លាយទិន្នន័យ ដោយសារវាធានាថាវិធីសាស្ត្រសមស្របត្រូវបានអនុវត្តលើសំណុំរងទិន្នន័យត្រឹមត្រូវ។ បំពង់បង្ហូរប្រេងគឺល្អសម្រាប់ប្រើក្នុងមុខងារកែតម្រូវឆ្លងដែន និងមុខងារលៃតម្រូវប៉ារ៉ាម៉ែត្រខ្ពស់។

ការគ្រប់គ្រងដោយចៃដន្យ
វត្ថុ scikit-learn មួយចំនួនគឺចៃដន្យ។ ទាំងនេះជាធម្មតាជាអ្នកប៉ាន់ស្មាន (ឧ. :class:`~sklearn.ensemble.RandomForestClassifier`) និងឧបករណ៍បំបែកសុពលភាពឆ្លង (ឧ. :class:`~sklearn.model_selection.KFold`)។ ភាពចៃដន្យនៃវត្ថុទាំងនេះត្រូវបានគ្រប់គ្រងតាមរយៈប៉ារ៉ាម៉ែត្រ random_state របស់ពួកគេ ដូចដែលបានពិពណ៌នានៅក្នុង :term:`សទ្ទានុក្រម <random_state>`។ ផ្នែកនេះពង្រីកនៅលើធាតុសទ្ទានុក្រម ហើយពិពណ៌នាអំពីការអនុវត្តល្អ និងបញ្ហាទូទៅ w.r.t. ប៉ារ៉ាម៉ែត្រដ៏កម្រនេះ។

ចំណាំ

សេចក្តីសង្ខេបនៃអនុសាសន៍

សម្រាប់ភាពរឹងមាំដ៏ប្រសើរបំផុតនៃលទ្ធផលឆ្លងកាត់សុពលភាព (CV) សូមឆ្លងកាត់ RandomState instances នៅពេលបង្កើតអ្នកប៉ាន់ស្មាន ឬទុក random_state ទៅគ្មាន។ ការបញ្ជូនចំនួនគត់ទៅកម្មវិធីបំបែក CV ជាធម្មតាជាជម្រើសដែលមានសុវត្ថិភាពបំផុត ហើយជាការប្រសើរ។ ការឆ្លងកាត់ករណី RandomState ទៅកាន់កម្មវិធីបំបែក ជួនកាលអាចមានប្រយោជន៍ ដើម្បីសម្រេចបានករណីប្រើប្រាស់ជាក់លាក់។ សម្រាប់អ្នកប៉ាន់ប្រមាណ និងអ្នកបំបែក ការឆ្លងកាត់ចំនួនគត់ធៀបនឹងការឆ្លងកាត់ឧទាហរណ៍មួយ (ឬគ្មាន) នាំទៅរកភាពខុសប្លែកគ្នាតិចតួច ប៉ុន្តែសំខាន់ជាពិសេសសម្រាប់នីតិវិធី CV ។ ភាពខុសគ្នាទាំងនេះមានសារៈសំខាន់ក្នុងការយល់នៅពេលរាយការណ៍លទ្ធផល។

សម្រាប់លទ្ធផលដែលអាចផលិតឡើងវិញបាននៅទូទាំងការប្រតិបត្តិ សូមដកការប្រើប្រាស់ណាមួយនៃ random_state=None។

ការប្រើប្រាស់ None ឬ RandomState instances និងការហៅម្តងហើយម្តងទៀតដើម្បីឱ្យសម និងបំបែក
ប៉ារ៉ាម៉ែត្រ Random_state កំណត់ថាតើការហៅច្រើនទៅ :term:`fit` (សម្រាប់អ្នកប៉ាន់ស្មាន) ឬទៅ :term:`split` (សម្រាប់អ្នកបំបែក CV) នឹងបង្កើតលទ្ធផលដូចគ្នានេះបើយោងតាមច្បាប់ទាំងនេះ៖

ប្រសិនបើចំនួនគត់ត្រូវបានឆ្លងកាត់ ការហៅសម ឬបំបែកច្រើនដងតែងតែផ្តល់លទ្ធផលដូចគ្នា។
ប្រសិនបើ None ឬ RandomState instance ត្រូវបានឆ្លងកាត់៖ សម និងបំបែកនឹងផ្តល់លទ្ធផលខុសៗគ្នារាល់ពេលដែលពួកគេត្រូវបានហៅ ហើយការហៅជាបន្តបន្ទាប់នឹងស្វែងរកប្រភពទាំងអស់នៃ entropy ។ គ្មានតម្លៃលំនាំដើមសម្រាប់ប៉ារ៉ាម៉ែត្រ random_state ទាំងអស់។
យើងនៅទីនេះបង្ហាញពីច្បាប់ទាំងនេះសម្រាប់អ្នកប៉ាន់ស្មាន និងអ្នកបំបែក CV ។

ចំណាំ

ចាប់តាំងពីការឆ្លងកាត់ random_state=គ្មានណាមួយស្មើនឹងការឆ្លងកាត់ឧទាហរណ៍ RandomState សកលពី numpy (random_state=np.random.mtrand._rand) យើងនឹងមិននិយាយឱ្យច្បាស់លាស់ទេនៅទីនេះ។ អ្វីគ្រប់យ៉ាងដែលអនុវត្តចំពោះឧទាហរណ៍ក៏អនុវត្តផងដែរចំពោះការប្រើប្រាស់គ្មាន។

អ្នកប៉ាន់ស្មាន
ឆ្លងកាត់ឧទាហរណ៍មានន័យថាការហៅសមច្រើនដងនឹងមិនផ្តល់លទ្ធផលដូចគ្នាទេ បើទោះបីជាការប៉ាន់ប្រមាណត្រូវបានបំពាក់លើទិន្នន័យដូចគ្នា និងជាមួយប៉ារ៉ាម៉ែត្រខ្ពស់ដូចគ្នា៖

>>> ពី sklearn.linear_model នាំចូល SGDClassifier
>>> ពី sklearn.datasets នាំចូល make_classification
>>> នាំចូល numpy ជា np

>>> rng = np.random.RandomState(0)
>>> X, y = make_classification(n_features=5, random_state=rng)
>>> sgd = SGDClassifier(random_state=rng)

>>> sgd.fit(X, y.coef_
array([[8.85418642, 4.79084103, -3.13077794, 8.11915045, -0.56479934]])

>>> sgd.fit(X, y.coef_
array([[6.70814003, 5.25291366, -7.55212743, 5.18197458, 1.37845099]])

យើង​អាច​មើល​ឃើញ​ពី​អត្ថបទ​ខាង​លើ​ដែល​ការ​ហៅ​ទូរសព្ទ​ម្ដង​ហើយ​ម្ដង​ទៀត sgd.fit បាន​ផលិត​ម៉ូដែល​ខុសៗ​គ្នា បើ​ទោះ​ជា​ទិន្នន័យ​ដូច​គ្នា​ក៏​ដោយ។ នេះគឺដោយសារតែ Random Number Generator (RNG) របស់អ្នកប៉ាន់ស្មានត្រូវបានប្រើប្រាស់ (មានន័យថាបានផ្លាស់ប្តូរ) នៅពេលដែលសមត្រូវបានហៅ ហើយ RNG ដែលផ្លាស់ប្តូរនេះនឹងត្រូវបានប្រើនៅក្នុងការហៅជាបន្តបន្ទាប់ដើម្បីឱ្យសម។ លើសពីនេះ វត្ថុ rng ត្រូវបានចែករំលែកនៅទូទាំងវត្ថុទាំងអស់ដែលប្រើវា ហើយជាលទ្ធផល វត្ថុទាំងនេះក្លាយជាអន្តរអាស្រ័យខ្លះ។ ឧទាហរណ៍ អ្នកប៉ាន់ស្មានពីរដែលចែករំលែកឧទាហរណ៍ RandomState ដូចគ្នានឹងមានឥទ្ធិពលលើគ្នាទៅវិញទៅមក ដូចដែលយើងនឹងឃើញនៅពេលក្រោយនៅពេលយើងពិភាក្សាអំពីការក្លូន។ ចំណុចនេះគឺសំខាន់ដែលត្រូវចងចាំនៅពេលបំបាត់កំហុស។

ប្រសិនបើយើងបានឆ្លងកាត់ចំនួនគត់ទៅប៉ារ៉ាម៉ែត្រ random_state នៃ :class:`~sklearn.linear_model.SGDClassifier` នោះ យើងនឹងទទួលបានគំរូដូចគ្នា ហើយដូច្នេះពិន្ទុដូចគ្នារាល់ពេល។ នៅពេលដែលយើងហុចចំនួនគត់ RNG ដូចគ្នាត្រូវបានប្រើនៅលើការហៅទូរស័ព្ទទាំងអស់ដើម្បីឱ្យសម។ អ្វីដែលកើតឡើងនៅខាងក្នុងគឺថាទោះបីជា RNG ត្រូវបានប្រើប្រាស់នៅពេលដែលសមត្រូវបានហៅក៏ដោយវាតែងតែត្រូវបានកំណត់ឡើងវិញទៅស្ថានភាពដើមរបស់វានៅដើមនៃការសម។

ឧបករណ៍បំបែក CV
អ្នកបំបែក CV ចៃដន្យមានឥរិយាបទស្រដៀងគ្នានៅពេលដែលឧទាហរណ៍ RandomState ត្រូវបានឆ្លងកាត់។ ការ​ហៅ​បំបែក​ច្រើន​ដង​ផ្តល់​ផល​បំបែក​ទិន្នន័យ​ខុស​គ្នា៖

>>> ពី sklearn.model_selection នាំចូល KFold
>>> នាំចូល numpy ជា np

>>> X = y = np.arange(10)
>>> rng = np.random.RandomState(0)
>>> cv = KFold(n_splits=2, shuffle=True, random_state=rng)

>>> សម្រាប់រថភ្លើង សាកល្បងក្នុង cv.split(X, y)៖
... បោះពុម្ព (រថភ្លើង សាកល្បង)
[0 3 5 6 7] [1 2 4 8 9]
[1 2 4 8 9] [0 3 5 6 7]

>>> សម្រាប់រថភ្លើង សាកល្បងក្នុង cv.split(X, y)៖
... បោះពុម្ព (រថភ្លើង សាកល្បង)
[0 4 6 7 8] [1 2 3 5 9]
[1 2 3 5 9] [0 4 6 7 8]
យើង​អាច​មើល​ឃើញ​ថា​ការ​បំបែក​គឺ​ខុស​ពី​ការ​បំបែក​ជា​លើក​ទី​ពីរ​ត្រូវ​បាន​គេ​ហៅ​ថា​។ នេះអាចនាំទៅរកលទ្ធផលដែលមិនរំពឹងទុក ប្រសិនបើអ្នកប្រៀបធៀបការអនុវត្តរបស់អ្នកប៉ាន់ស្មានច្រើនដោយការហៅបំបែកជាច្រើនដង ដូចដែលយើងនឹងឃើញនៅក្នុងផ្នែកបន្ទាប់។

ឧបាយកល និងឧបាយកលទូទៅ
ខណៈពេលដែលច្បាប់ដែលគ្រប់គ្រងប៉ារ៉ាម៉ែត្រ random_state ហាក់បីដូចជាសាមញ្ញក៏ដោយ ពួកវាមានផលប៉ះពាល់តិចតួចមួយចំនួន។ ក្នុងករណីខ្លះ នេះអាចនាំឱ្យមានការសន្និដ្ឋានខុស។

អ្នកប៉ាន់ស្មាន
ប្រភេទ `random_state` ផ្សេងគ្នានាំទៅរកនីតិវិធីផ្ទៀងផ្ទាត់ឆ្លងដែនផ្សេងៗគ្នា

អាស្រ័យលើប្រភេទនៃប៉ារ៉ាម៉ែត្រ random_state អ្នកប៉ាន់ស្មាននឹងមានឥរិយាបទខុសគ្នា ជាពិសេសនៅក្នុងនីតិវិធីឆ្លងកាត់សុពលភាព។ ពិចារណា​ផ្នែក​ខាង​ក្រោម៖

>>> ពី sklearn.ensemble នាំចូល RandomForestClassifier
>>> ពី sklearn.datasets នាំចូល make_classification
>>> ពី sklearn.model_selection នាំចូល cross_val_score
>>> នាំចូល numpy ជា np

>>> X, y = make_classification(random_state=0)

>>> rf_123 = RandomForestClassifier(random_state=123)
>>> cross_val_score(rf_123, X, y)
array([0.85, 0.95, 0.95, 0.9, 0.9])

>>> rf_inst = RandomForestClassifier(random_state=np.random.RandomState(0))
>>> cross_val_score(rf_inst, X, y)
array([0.9, 0.95, 0.95, 0.9, 0.9])

យើងឃើញថាពិន្ទុឆ្លងកាត់សុពលភាពនៃ rf_123 និង rf_inst គឺខុសគ្នា ដូចដែលគួរត្រូវបានរំពឹងទុក ដោយសារយើងមិនបានឆ្លងកាត់ប៉ារ៉ាម៉ែត្រ random_state ដូចគ្នា។ ទោះជាយ៉ាងណាក៏ដោយ ភាពខុសគ្នារវាងពិន្ទុទាំងនេះគឺមានភាពស្រពិចស្រពិលជាងវាមើលទៅ ហើយនីតិវិធីឆ្លងកាត់សុពលភាពដែលត្រូវបានអនុវត្តដោយ :func:`~sklearn.model_selection.cross_val_score` ខុសគ្នាខ្លាំងនៅក្នុងករណីនីមួយៗ៖

ចាប់តាំងពី rf_123 ត្រូវបានឆ្លងកាត់ចំនួនគត់ រាល់ការហៅឱ្យសមប្រើ RNG ដូចគ្នា៖ នេះមានន័យថា លក្ខណៈចៃដន្យទាំងអស់របស់អ្នកប៉ាន់ស្មានព្រៃចៃដន្យនឹងដូចគ្នាសម្រាប់ 5 ដងនីមួយៗនៃនីតិវិធី CV ។ ជាពិសេស សំណុំរង (ជ្រើសរើសដោយចៃដន្យ) នៃលក្ខណៈពិសេសរបស់អ្នកប៉ាន់ស្មាននឹងដូចគ្នានៅគ្រប់ផ្នត់ទាំងអស់។
ចាប់តាំងពី rf_inst ត្រូវបានឆ្លងកាត់ឧទាហរណ៍ RandomState ការហៅនីមួយៗដើម្បីឱ្យសមចាប់ផ្តើមពី RNG ផ្សេងគ្នា។ ជាលទ្ធផល សំណុំរងចៃដន្យនៃលក្ខណៈពិសេសនឹងខុសគ្នាសម្រាប់ផ្នត់នីមួយៗ។
ខណៈពេលដែលការប៉ាន់ស្មានថេរ RNG ឆ្លងកាត់ផ្នត់គឺមិនខុសទេ ជាធម្មតាយើងចង់បានលទ្ធផល CV ដែលរឹងមាំ w.r.t. ភាពចៃដន្យរបស់អ្នកប៉ាន់ស្មាន។ ជាលទ្ធផល ការឆ្លងកាត់ឧទាហរណ៍មួយជំនួសឱ្យចំនួនគត់ប្រហែលជាល្អជាង ព្រោះវានឹងអនុញ្ញាតឱ្យការប៉ាន់ប្រមាណ RNG ប្រែប្រួលសម្រាប់ផ្នត់នីមួយៗ។

ចំណាំ

នៅទីនេះ :func:`~sklearn.model_selection.cross_val_score` នឹងប្រើកម្មវិធីបំបែក CV ដែលមិនចៃដន្យ (ដូចលំនាំដើម) ដូច្នេះអ្នកប៉ាន់ស្មានទាំងពីរនឹងត្រូវបានវាយតម្លៃលើការបំបែកដូចគ្នា។ ផ្នែកនេះមិនមែននិយាយអំពីភាពប្រែប្រួលនៅក្នុងការបំបែកនោះទេ។ ដូចគ្នានេះផងដែរ ថាតើយើងឆ្លងចំនួនគត់ ឬឧទាហរណ៍ទៅ :func:`~sklearn.datasets.make_classification` គឺមិនពាក់ព័ន្ធសម្រាប់គោលបំណងគំនូររបស់យើងទេ៖ អ្វីដែលសំខាន់គឺអ្វីដែលយើងឆ្លងទៅ :class:`~sklearn.ensemble.RandomForestClassifier` អ្នកប៉ាន់ស្មាន។

ក្លូន

ផលប៉ះពាល់ដ៏ស្រាលមួយទៀតនៃការឆ្លងកាត់ករណី RandomState គឺរបៀបដែល :func:`~sklearn.clone` នឹងដំណើរការ៖

>>> ពី sklearn import clone
>>> ពី sklearn.ensemble នាំចូល RandomForestClassifier
>>> នាំចូល numpy ជា np

>>> rng = np.random.RandomState(0)
>>> a = RandomForestClassifier(random_state=rng)
>>> b = ក្លូន(a)
ដោយសារឧទាហរណ៍ RandomState ត្រូវបានបញ្ជូនទៅ a និង b មិនមែនជាក្លូនក្នុងន័យតឹងរឹងទេ ប៉ុន្តែជាក្លូនក្នុងន័យស្ថិតិ៖ a និង b នឹងនៅតែជាគំរូផ្សេងគ្នា សូម្បីតែនៅពេលហៅ fit(X, y) នៅលើទិន្នន័យដូចគ្នា . លើសពីនេះទៅទៀត a និង b នឹងមានឥទ្ធិពលលើគ្នាទៅវិញទៅមក ចាប់តាំងពីពួកគេចែករំលែក RNG ខាងក្នុងដូចគ្នា៖ ការហៅ a.fit នឹងប្រើប្រាស់ RNG របស់ b ហើយការហៅ b.fit នឹងប្រើប្រាស់ RNG របស់ a ព្រោះវាដូចគ្នា។ ប៊ីតនេះជាការពិតសម្រាប់អ្នកប៉ាន់ស្មានណាមួយដែលចែករំលែកប៉ារ៉ាម៉ែត្រ random_state; វាមិនជាក់លាក់ចំពោះក្លូនទេ។

ប្រសិនបើចំនួនគត់ត្រូវបានឆ្លងកាត់ នោះ a និង b នឹងក្លាយជាក្លូនពិតប្រាកដ ហើយពួកវានឹងមិនមានឥទ្ធិពលលើគ្នាទៅវិញទៅមកទេ។

ការព្រមាន

ទោះបីជា :func:`~sklearn.clone` កម្រត្រូវបានប្រើប្រាស់ក្នុងកូដអ្នកប្រើប្រាស់ក៏ដោយ វាត្រូវបានហៅយ៉ាងទូលំទូលាយនៅទូទាំង scikit-learn codebase៖ ជាពិសេស អ្នកប៉ាន់ស្មានមេតាភាគច្រើនដែលទទួលយកការប៉ាន់ប្រមាណមិនសមស្រប ហៅថា :func:`~sklearn.clone ` ខាងក្នុង (:class:`~sklearn.model_selection.GridSearchCV`, :class:`~sklearn.ensemble.StackingClassifier`, :class:`~sklearn.calibration.CalibratedClassifierCV` ។ល។)

ឧបករណ៍បំបែក CV
នៅពេលឆ្លងកាត់ឧទាហរណ៍ RandomState អ្នកបំបែក CV ផ្តល់ការបំបែកខុសៗគ្នារាល់ពេលដែលការបំបែកត្រូវបានគេហៅថា។ នៅពេលប្រៀបធៀបការប៉ាន់ប្រមាណផ្សេងៗគ្នា នេះអាចនាំទៅដល់ការប៉ាន់ប្រមាណលើសភាពខុសគ្នានៃភាពខុសគ្នានៃការអនុវត្តរវាងអ្នកប៉ាន់ស្មាន៖

>>> ពី sklearn.naive_bayes នាំចូល GaussianNB
>>> ពី sklearn.discriminant_analysis នាំចូល LinearDiscriminantAnalysis
>>> ពី sklearn.datasets នាំចូល make_classification
>>> ពី sklearn.model_selection នាំចូល KFold
>>> ពី sklearn.model_selection នាំចូល cross_val_score
>>> នាំចូល numpy ជា np

>>> rng = np.random.RandomState(0)
>>> X, y = make_classification(random_state=rng)
>>> cv = KFold(សាប់=True, random_state=rng)
>>> lda = LinearDiscriminantAnalysis()
>>> nb = GaussianNB()

>>> សម្រាប់ est in (lda, nb):
... print(cross_val_score(est, X, y, cv=cv))
[0.8 0.75 0.75 0.7 0.85]
[0.85 0.95 0.95 0.85 0.95]

ការប្រៀបធៀបដោយផ្ទាល់នូវការអនុវត្តនៃ :class:`~sklearn.discriminant_analysis.LinearDiscriminantAnalysis` ការប៉ាន់ប្រមាណ :class:`~sklearn.naive_bayes.GaussianNB` ការប៉ាន់ប្រមាណនៅលើផ្នត់នីមួយៗនឹងមានកំហុស៖ ការបំបែកដែលអ្នកវាយតម្លៃខុសគ្នា . ជាការពិតណាស់ :func:`~sklearn.model_selection.cross_val_score` នឹងហៅខាងក្នុង cv.split នៅលើឧទាហរណ៍ :class:`~sklearn.model_selection.KFold` ប៉ុន្តែការបំបែកនឹងខុសគ្នារាល់ពេល។ នេះក៏ជាការពិតសម្រាប់ឧបករណ៍ណាមួយដែលដំណើរការការជ្រើសរើសគំរូតាមរយៈការបញ្ជាក់ឆ្លងដែន ឧ. :class:`~sklearn.model_selection.GridSearchCV` និង :class:`~sklearn.model_selection.RandomizedSearchCV`: ពិន្ទុមិនអាចប្រៀបធៀបបាន បត់ទៅបត់ តាមរយៈការហៅផ្សេងៗគ្នាទៅកាន់ search.fit ចាប់តាំងពី cv.split នឹងត្រូវបានគេហៅថាច្រើន ដង។ ទោះយ៉ាងណាក៏ដោយ នៅក្នុងការហៅទៅ search.fit តែមួយដង ការប្រៀបធៀប fold-to-fold គឺអាចធ្វើទៅបាន ដោយសារអ្នកប៉ាន់ស្មានការស្វែងរកហៅ cv.split តែម្តងប៉ុណ្ណោះ។

សម្រាប់​លទ្ធផល​ផ្នត់​ទៅ​ផ្នត់​ដែល​អាច​ប្រៀបធៀប​បាន​ក្នុង​គ្រប់​សេណារីយ៉ូ មួយ​គួរតែ​ហុច​ចំនួន​គត់​ទៅ​កម្មវិធី​បំបែក​ប្រវត្តិរូប៖ cv = KFold(shuffle=True, random_state=0)។

ចំណាំ

ខណៈពេលដែលការប្រៀបធៀប fold-to-fold មិនត្រូវបានណែនាំឱ្យប្រើជាមួយ RandomState នោះទេ ទោះជាយ៉ាងណាក៏ដោយ មនុស្សម្នាក់អាចរំពឹងថាពិន្ទុជាមធ្យមអនុញ្ញាតឱ្យធ្វើការសន្និដ្ឋានថាតើការប៉ាន់ប្រមាណមួយល្អជាងមួយផ្សេងទៀត ដរាបណាការបត់ និងទិន្នន័យគ្រប់គ្រាន់ត្រូវបានប្រើប្រាស់។

ចំណាំ

អ្វីដែលសំខាន់នៅក្នុងឧទាហរណ៍នេះគឺអ្វីដែលត្រូវបានបញ្ជូនទៅ :class:`~sklearn.model_selection.KFold`។ ថាតើយើងឆ្លងកាត់ឧទាហរណ៍ RandomState ឬចំនួនគត់ទៅ :func:`~sklearn.datasets.make_classification` គឺមិនពាក់ព័ន្ធសម្រាប់គោលបំណងគំនូររបស់យើងទេ។ ដូចគ្នានេះផងដែរ ទាំង :class:`~sklearn.discriminant_analysis.LinearDiscriminantAnalysis` ឬ :class:`~sklearn.naive_bayes.GaussianNB` គឺជាការប៉ាន់ប្រមាណចៃដន្យ។

អនុសាសន៍ទូទៅ
ទទួលបានលទ្ធផលដែលអាចផលិតឡើងវិញបានតាមរយៈការប្រតិបត្តិជាច្រើន។
ដើម្បីទទួលបានលទ្ធផលដែលអាចផលិតឡើងវិញបាន (ឧ. ថេរ) ឆ្លងកាត់ការប្រតិបត្តិកម្មវិធីជាច្រើន យើងត្រូវលុបការប្រើប្រាស់ទាំងអស់នៃ random_state=None ដែលជាលំនាំដើម។ មធ្យោបាយដែលបានណែនាំគឺត្រូវប្រកាសអថេរ rng នៅផ្នែកខាងលើនៃកម្មវិធី ហើយបញ្ជូនវាទៅវត្ថុណាមួយដែលទទួលយកប៉ារ៉ាម៉ែត្រ random_state៖

>>> ពី sklearn.ensemble នាំចូល RandomForestClassifier
>>> ពី sklearn.datasets នាំចូល make_classification
>>> ពី sklearn.model_selection import train_test_split
>>> នាំចូល numpy ជា np

>>> rng = np.random.RandomState(0)
>>> X, y = make_classification(random_state=rng)
>>> rf = RandomForestClassifier(random_state=rng)
>>> X_train, X_test, y_train, y_test = train_test_split(X, y,
... random_state=rng)
>>> rf.fit(X_train, y_train) ពិន្ទុ(X_test, y_test)
0.84
ឥឡូវនេះយើងត្រូវបានធានាថាលទ្ធផលនៃស្គ្រីបនេះនឹងតែងតែជា 0.84 ទោះបីជាយើងដំណើរការវាប៉ុន្មានដងក៏ដោយ។ ការផ្លាស់ប្តូរអថេរ rng សកលទៅតម្លៃផ្សេងគួរតែប៉ះពាល់ដល់លទ្ធផល ដូចដែលបានរំពឹងទុក។

វាក៏អាចធ្វើទៅបានដើម្បីប្រកាសអថេរ rng ជាចំនួនគត់។ ទោះយ៉ាងណាក៏ដោយ នេះអាចនាំទៅរកលទ្ធផលនៃសុពលភាពឆ្លងដែលមិនសូវរឹងមាំ ដូចដែលយើងនឹងឃើញនៅក្នុងផ្នែកបន្ទាប់។

ចំណាំ

យើង​មិន​ណែនាំ​ឱ្យ​កំណត់​គ្រាប់ពូជ​លេខ​សកល​ដោយ​ហៅ​ទៅ np.random.seed(0) ទេ។ សូមមើលនៅទីនេះសម្រាប់ការពិភាក្សា។

ភាពរឹងមាំនៃលទ្ធផលឆ្លងកាត់សុពលភាព
នៅពេលយើងវាយតម្លៃការអនុវត្តការប៉ាន់ប្រមាណចៃដន្យដោយការផ្ទៀងផ្ទាត់ឆ្លង យើងចង់ធ្វើឱ្យប្រាកដថាអ្នកប៉ាន់ស្មានអាចផ្តល់ការព្យាករណ៍ត្រឹមត្រូវសម្រាប់ទិន្នន័យថ្មី ប៉ុន្តែយើងក៏ចង់ធ្វើឱ្យប្រាកដថាឧបករណ៍ប៉ាន់ស្មានគឺរឹងមាំ w.r.t. ការចាប់ផ្តើមចៃដន្យរបស់វា។ ជាឧទាហរណ៍ យើងចង់ឱ្យការចាប់ផ្តើមទម្ងន់ចៃដន្យនៃ :class:`~sklearn.linear_model.SGDCLassifier` ឱ្យមានភាពជាប់លាប់ក្នុងគ្រប់ផ្នត់ទាំងអស់៖ បើមិនដូច្នេះទេ នៅពេលដែលយើងបណ្តុះបណ្តាលអ្នកប៉ាន់ស្មាននោះលើទិន្នន័យថ្មី យើងអាចទទួលបានសំណាងមិនល្អ ហើយការចាប់ផ្តើមដោយចៃដន្យ អាចនាំឱ្យដំណើរការមិនល្អ។ ស្រដៀងគ្នានេះដែរ យើងចង់ឱ្យព្រៃចៃដន្យមួយមានភាពរឹងមាំ w.r.t សំណុំនៃលក្ខណៈពិសេសដែលបានជ្រើសរើសដោយចៃដន្យដែលដើមឈើនីមួយៗនឹងប្រើប្រាស់។

សម្រាប់ហេតុផលទាំងនេះ វាជាការប្រសើរក្នុងការវាយតម្លៃដំណើរការឆ្លងដែនដោយអនុញ្ញាតឱ្យអ្នកវាយតម្លៃប្រើ RNG ផ្សេងគ្នានៅលើផ្នត់នីមួយៗ។ នេះត្រូវបានធ្វើដោយឆ្លងកាត់ឧទាហរណ៍ RandomState (ឬគ្មាន) ទៅកាន់ការចាប់ផ្តើមប៉ាន់ស្មាន។

នៅពេលដែលយើងឆ្លងកាត់ចំនួនគត់ អ្នកប៉ាន់ស្មាននឹងប្រើ RNG ដូចគ្នានៅលើផ្នត់នីមួយៗ៖ ប្រសិនបើអ្នកប៉ាន់ស្មានដំណើរការល្អ (ឬអាក្រក់) ដូចដែលបានវាយតម្លៃដោយ CV វាអាចដោយសារតែយើងទទួលបានសំណាង (ឬសំណាង) ជាមួយនឹងគ្រាប់ពូជជាក់លាក់នោះ។ ករណីឆ្លងកាត់នាំឱ្យលទ្ធផល CV កាន់តែរឹងមាំ ហើយធ្វើឱ្យការប្រៀបធៀបរវាងក្បួនដោះស្រាយផ្សេងៗមានភាពយុត្តិធម៌ជាងមុន។ វាក៏ជួយកំណត់ការល្បួងក្នុងការព្យាបាល RNG របស់អ្នកប៉ាន់ប្រមាណថាជា hyper-parameter ដែលអាចលៃតម្រូវបាន។

មិនថាយើងឆ្លងកាត់ RandomState instances ឬ integers ទៅកាន់ CV splitter មិនប៉ះពាល់ដល់ភាពរឹងមាំនោះទេ ដរាបណាការបំបែកគឺត្រូវបានហៅតែម្តងប៉ុណ្ណោះ។ នៅពេលដែលការបំបែកត្រូវបានគេហៅថាច្រើនដង ការប្រៀបធៀបពីមួយទៅមួយដងគឺមិនអាចធ្វើទៅបានទៀតទេ។ ជាលទ្ធផល ការឆ្លងកាត់ចំនួនគត់ទៅ CV splitter ជាធម្មតាមានសុវត្ថិភាពជាង និងគ្របដណ្តប់ករណីប្រើប្រាស់ភាគច្រើន។